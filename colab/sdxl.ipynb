{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeerafle/comfyui-scripts/blob/main/colab/sdxl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "!apt -y update -qq\n",
        "!apt -y install -qq aria2\n",
        "# !pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "# !pip install -q xformers==0.0.16 triton==2.0.0 -U\n",
        "# !pip install -q mediapipe==0.9.1.0 addict yapf fvcore omegaconf\n",
        "\n",
        "!git clone git@github.com:comfyanonymous/ComfyUI.git\n",
        "%cd /content/ComfyUI\n",
        "!pip install -q -r requirements.txt\n",
        "!git reset --hard\n",
        "\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared-linux-amd64 && chmod 777 /content/cloudflared-linux-amd64\n",
        "import atexit, requests, subprocess, time, re, os\n",
        "from random import randint\n",
        "from threading import Timer\n",
        "from queue import Queue\n",
        "def cloudflared(port, metrics_port, output_queue):\n",
        "    atexit.register(lambda p: p.terminate(), subprocess.Popen(['/content/cloudflared-linux-amd64', 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT))\n",
        "    attempts, tunnel_url = 0, None\n",
        "    while attempts < 10 and not tunnel_url:\n",
        "        attempts += 1\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            tunnel_url = re.search(\"(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)\", requests.get(f'http://127.0.0.1:{metrics_port}/metrics').text).group(\"url\")\n",
        "        except:\n",
        "            pass\n",
        "    if not tunnel_url:\n",
        "        raise Exception(\"Can't connect to Cloudflare Edge\")\n",
        "    output_queue.put(tunnel_url)\n",
        "output_queue, metrics_port = Queue(), randint(8100, 9000)\n",
        "thread = Timer(2, cloudflared, args=(8188, metrics_port, output_queue))\n",
        "thread.start()\n",
        "thread.join()\n",
        "tunnel_url = output_queue.get()\n",
        "os.environ['webui_url'] = tunnel_url\n",
        "print(tunnel_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.env['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.env['CIVITAI_TOKEN'] = userdata.get('CIVITAI_TOKEN')"
      ],
      "metadata": {
        "id": "JQL_oY5HfTar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Set up environment\n",
        "COMFYUI_DIR=/content/ComfyUI\n",
        "\n",
        "# Model arrays\n",
        "CHECKPOINT_MODELS=(\n",
        "    \"https://civitai.com/api/download/models/1759168?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        ")\n",
        "\n",
        "LORA_MODELS=(\n",
        "    \"https://civitai.com/api/download/models/864266?type=Model&format=SafeTensor\"\n",
        "    \"https://civitai.com/api/download/models/135867?type=Model&format=SafeTensor\"\n",
        "    \"https://civitai.com/api/download/models/302404?type=Model&format=SafeTensor\"\n",
        "    \"https://civitai.com/api/download/models/128461?type=Model&format=SafeTensor\"\n",
        "    \"https://civitai.com/api/download/models/287900?type=Model&format=SafeTensor\"\n",
        ")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "mkdir -p \"${COMFYUI_DIR}/models/checkpoints\"\n",
        "mkdir -p \"${COMFYUI_DIR}/models/loras\"\n",
        "\n",
        "# Download function using aria2c\n",
        "function download_model() {\n",
        "    local url=\"$1\"\n",
        "    local destination=\"$2\"\n",
        "    local model_type=\"$3\"\n",
        "\n",
        "    echo \"Downloading $model_type: $url\"\n",
        "    echo \"Destination: $destination\"\n",
        "\n",
        "    if [[ -n $HF_TOKEN && $url =~ ^https://([a-zA-Z0-9_-]+\\.)?huggingface\\.co(/|$|\\?) ]]; then\n",
        "        # HuggingFace download with authorization header\n",
        "        aria2c --header=\"Authorization: Bearer $HF_TOKEN\" \\\n",
        "               --content-disposition-default-utf8=true \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" \"$url\"\n",
        "    elif [[ -n $CIVITAI_TOKEN && $url =~ ^https://([a-zA-Z0-9_-]+\\.)?civitai\\.com(/|$|\\?) ]]; then\n",
        "        # Civitai download with token parameter\n",
        "        if [[ $url == *\"?\"* ]]; then\n",
        "            download_url=\"${url}&token=${CIVITAI_TOKEN}\"\n",
        "        else\n",
        "            download_url=\"${url}?token=${CIVITAI_TOKEN}\"\n",
        "        fi\n",
        "        aria2c --content-disposition-default-utf8=true \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" \"$download_url\"\n",
        "    else\n",
        "        # Generic download\n",
        "        aria2c --content-disposition-default-utf8=true \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" \"$url\"\n",
        "    fi\n",
        "\n",
        "    if [ $? -eq 0 ]; then\n",
        "        echo \"✓ Successfully downloaded $model_type\"\n",
        "    else\n",
        "        echo \"✗ Failed to download $model_type: $url\"\n",
        "    fi\n",
        "    echo \"----------------------------------------\"\n",
        "}\n",
        "\n",
        "# Download checkpoint models\n",
        "echo \"Starting checkpoint model downloads...\"\n",
        "echo \"========================================\"\n",
        "for url in \"${CHECKPOINT_MODELS[@]}\"; do\n",
        "    download_model \"$url\" \"${COMFYUI_DIR}/models/checkpoints\" \"Checkpoint Model\"\n",
        "done\n",
        "\n",
        "# Download LoRA models\n",
        "echo \"\"\n",
        "echo \"Starting LoRA model downloads...\"\n",
        "echo \"=================================\"\n",
        "for url in \"${LORA_MODELS[@]}\"; do\n",
        "    download_model \"$url\" \"${COMFYUI_DIR}/models/loras\" \"LoRA Model\"\n",
        "done\n",
        "\n",
        "echo \"\"\n",
        "echo \"All downloads completed!\"\n",
        "echo \"========================\"\n",
        "echo \"Checkpoint models saved to: ${COMFYUI_DIR}/models/checkpoints\"\n",
        "echo \"LoRA models saved to: ${COMFYUI_DIR}/models/loras\"\n",
        "\n",
        "# Optional: List downloaded files\n",
        "echo \"\"\n",
        "echo \"Downloaded checkpoint models:\"\n",
        "ls -la \"${COMFYUI_DIR}/models/checkpoints/\"\n",
        "echo \"\"\n",
        "echo \"Downloaded LoRA models:\"\n",
        "ls -la \"${COMFYUI_DIR}/models/loras/\""
      ],
      "metadata": {
        "id": "AUV36yTVe-be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dont-print-server"
      ],
      "metadata": {
        "id": "5evLRlbLfyFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}